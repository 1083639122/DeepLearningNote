{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"因为 ResNet 提出了跨层链接的思想，这直接影响了随后出现的卷积网络架构，其中最有名的就是 cvpr 2017 的 best paper，DenseNet。\n\nDenseNet 和 ResNet 不同在于 ResNet 是跨层求和，而 DenseNet 是跨层将特征在通道维度进行拼接","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"一如既往的导入库，写训练函数，读取并预处理数据集","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torchvision.datasets import mnist\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:00:01.487283Z","iopub.execute_input":"2021-10-07T11:00:01.488029Z","iopub.status.idle":"2021-10-07T11:00:05.985212Z","shell.execute_reply.started":"2021-10-07T11:00:01.487939Z","shell.execute_reply":"2021-10-07T11:00:05.984461Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\n\ndef get_acc(output, label):\n    total = output.shape[0]\n    _, pred_label = output.max(1)\n    num_correct = (pred_label == label).sum().data\n    return num_correct / total\n\n\ndef train(net, train_data, valid_data, num_epochs, optimizer, criterion):\n    if torch.cuda.is_available():\n        net = net.cuda()\n    prev_time = datetime.now()\n    for epoch in range(num_epochs):\n        train_loss = 0\n        train_acc = 0\n        net = net.train()\n        for im, label in train_data:\n            if torch.cuda.is_available():\n                im = Variable(im.cuda())  # (bs, 3, h, w)\n                label = Variable(label.cuda())  # (bs, h, w)\n            else:\n                im = Variable(im)\n                label = Variable(label)\n            # forward\n            output = net(im)\n            loss = criterion(output, label)\n            # backward\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.data\n            train_acc += get_acc(output, label)\n\n        cur_time = datetime.now()\n        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n        m, s = divmod(remainder, 60)\n        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n        if valid_data is not None:\n            valid_loss = 0\n            valid_acc = 0\n            net = net.eval()\n            for im, label in valid_data:\n                if torch.cuda.is_available():\n                    im = Variable(im.cuda())\n                    label = Variable(label.cuda())\n                else:\n                    im = Variable(im)\n                    label = Variable(label)\n                output = net(im)\n                loss = criterion(output, label)\n                valid_loss += loss.data\n                valid_acc += get_acc(output, label)\n            epoch_str = (\n                \"Epoch %d. Train Loss: %f, Train Acc: %f, Valid Loss: %f, Valid Acc: %f, \"\n                % (epoch, train_loss / len(train_data),\n                   train_acc / len(train_data), valid_loss / len(valid_data),\n                   valid_acc / len(valid_data)))\n        else:\n            epoch_str = (\"Epoch %d. Train Loss: %f, Train Acc: %f, \" %\n                         (epoch, train_loss / len(train_data),\n                          train_acc / len(train_data)))\n        prev_time = cur_time\n        print(epoch_str + time_str)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:00:05.986755Z","iopub.execute_input":"2021-10-07T11:00:05.987041Z","iopub.status.idle":"2021-10-07T11:00:06.002156Z","shell.execute_reply.started":"2021-10-07T11:00:05.987005Z","shell.execute_reply":"2021-10-07T11:00:06.001201Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def data_tf(x):\n    x = np.array(x, dtype='float32') / 255\n    x = (x - 0.5) / 0.5 # 数据预处理，标准化\n    x=np.array([x.tolist()])\n    x = torch.from_numpy(x)    \n    return x\n\nfrom torchvision.datasets import mnist # 导入 pytorch 内置的 mnist 数据\ntrain_set = mnist.MNIST('./data', train=True, transform=data_tf,download=True) # 重新载入数据集，申明定义的数据变换\ntest_set = mnist.MNIST('./data', train=False, transform=data_tf,download=True)\ntrain_data = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\ntest_data = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:00:06.003553Z","iopub.execute_input":"2021-10-07T11:00:06.003894Z","iopub.status.idle":"2021-10-07T11:00:08.302913Z","shell.execute_reply.started":"2021-10-07T11:00:06.003844Z","shell.execute_reply":"2021-10-07T11:00:08.302062Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"查看一个batch数据的尺寸，便于网络的设计","metadata":{}},{"cell_type":"code","source":"x=torch.tensor([])\nfor i,j in train_data:\n    x=i\n    break\nprint(x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:00:08.305290Z","iopub.execute_input":"2021-10-07T11:00:08.305751Z","iopub.status.idle":"2021-10-07T11:00:08.347695Z","shell.execute_reply.started":"2021-10-07T11:00:08.305713Z","shell.execute_reply":"2021-10-07T11:00:08.346987Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"接下来设计实现一个densen block","metadata":{}},{"cell_type":"code","source":"# 首先定义一个卷积块，这个卷积块的顺序是 bn -> relu -> conv\ndef conv_block(in_channel, out_channel):\n    layer = nn.Sequential(\n        nn.BatchNorm2d(in_channel),\n        nn.ReLU(True),\n        nn.Conv2d(in_channel, out_channel, 3, padding=1, bias=False)\n    )\n    return layer","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:00:08.348959Z","iopub.execute_input":"2021-10-07T11:00:08.349325Z","iopub.status.idle":"2021-10-07T11:00:08.354662Z","shell.execute_reply.started":"2021-10-07T11:00:08.349291Z","shell.execute_reply":"2021-10-07T11:00:08.353934Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# dense block 将每次的卷积的输出称为 `growth_rate`，因为如果输入是 `in_channel`，有 n 层，那么输出就是 `in_channel + n * growh_rate`\nclass dense_block(nn.Module):\n    def __init__(self, in_channel, growth_rate, num_layers):\n        super(dense_block, self).__init__()\n        block = []\n        channel = in_channel\n        for i in range(num_layers):\n            block.append(conv_block(channel, growth_rate))\n            channel += growth_rate\n            \n        self.net = nn.Sequential(*block)\n        \n    def forward(self, x):\n        for layer in self.net:\n            out = layer(x)\n            x = torch.cat((out, x), dim=1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:00:08.356359Z","iopub.execute_input":"2021-10-07T11:00:08.357009Z","iopub.status.idle":"2021-10-07T11:00:08.365604Z","shell.execute_reply.started":"2021-10-07T11:00:08.356970Z","shell.execute_reply":"2021-10-07T11:00:08.364834Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"DenseNet 中还有一个模块叫过渡层（transition block），因为 DenseNet 会不断地对维度进行拼接， 所以当层数很高的时候，输出的通道数就会越来越大，参数和计算量也会越来越大，为了避免这个问题，需要引入过渡层将输出通道降低下来，同时也将输入的长宽减半，这个过渡层可以使用 1 x 1 的卷积","metadata":{}},{"cell_type":"code","source":"def transition(in_channel, out_channel):\n    trans_layer = nn.Sequential(\n        nn.BatchNorm2d(in_channel),\n        nn.ReLU(True),\n        nn.Conv2d(in_channel, out_channel, 1),\n        nn.AvgPool2d(2, 2)\n    )\n    return trans_layer","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:00:08.366849Z","iopub.execute_input":"2021-10-07T11:00:08.367585Z","iopub.status.idle":"2021-10-07T11:00:08.375931Z","shell.execute_reply.started":"2021-10-07T11:00:08.367546Z","shell.execute_reply":"2021-10-07T11:00:08.375106Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"block1 = nn.Sequential(\n            nn.Conv2d(1, 64, 7, 2, 3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            nn.MaxPool2d(3, 2, padding=1)\n        )","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:00:08.377334Z","iopub.execute_input":"2021-10-07T11:00:08.377680Z","iopub.status.idle":"2021-10-07T11:00:08.391616Z","shell.execute_reply.started":"2021-10-07T11:00:08.377645Z","shell.execute_reply":"2021-10-07T11:00:08.390812Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"block=[]\nblock.append(dense_block(64, 21, 16))\nblock.append(transition(400, 400 // 2)) # 通过 transition 层将大小减半，通道数减半\nblock2 = nn.Sequential(*block)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:00:08.393135Z","iopub.execute_input":"2021-10-07T11:00:08.393405Z","iopub.status.idle":"2021-10-07T11:00:08.411773Z","shell.execute_reply.started":"2021-10-07T11:00:08.393371Z","shell.execute_reply":"2021-10-07T11:00:08.411055Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"block3 = nn.Sequential(*[])\nblock3.add_module('bn', nn.BatchNorm2d(200))\nblock3.add_module('relu', nn.ReLU(True))\nblock3.add_module('avg_pool', nn.AvgPool2d(2))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:00:08.414348Z","iopub.execute_input":"2021-10-07T11:00:08.414645Z","iopub.status.idle":"2021-10-07T11:00:08.419762Z","shell.execute_reply.started":"2021-10-07T11:00:08.414610Z","shell.execute_reply":"2021-10-07T11:00:08.418821Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(\"1:\",x.shape)\nx=block1(x.float())\nprint(\"2:\",x.shape)\nx=block2(x)\nprint(\"3:\",x.shape)\nx=block3(x)\nprint(\"4:\",x.shape)\nx = x.view(x.shape[0], -1)\nprint(\"4:\",x.shape)\nx=nn.Linear(200, 10)(x)\nprint(\"10:\",x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:00:08.421432Z","iopub.execute_input":"2021-10-07T11:00:08.421959Z","iopub.status.idle":"2021-10-07T11:00:08.726700Z","shell.execute_reply.started":"2021-10-07T11:00:08.421924Z","shell.execute_reply":"2021-10-07T11:00:08.725989Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class densenet(nn.Module):\n    def __init__(self, in_channel, num_classes):\n        super(densenet, self).__init__()\n        self.block1 = nn.Sequential(\n            nn.Conv2d(1, 64, 7, 2, 3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            nn.MaxPool2d(3, 2, padding=1)\n        )\n        \n        block=[]\n        block.append(dense_block(64, 21, 16))\n        block.append(transition(400, 400 // 2)) # 通过 transition 层将大小减半，通道数减半\n        self.block2 = nn.Sequential(*block)\n        \n        self.block3 = nn.Sequential(*[])\n        self.block3.add_module('bn', nn.BatchNorm2d(200))\n        self.block3.add_module('relu', nn.ReLU(True))\n        self.block3.add_module('avg_pool', nn.AvgPool2d(2))\n        \n        \n        self.classifier = nn.Linear(200, num_classes)\n    \n    def forward(self, x):\n        x=x.float()\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = x.view(x.shape[0], -1)\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:00:08.728169Z","iopub.execute_input":"2021-10-07T11:00:08.728443Z","iopub.status.idle":"2021-10-07T11:00:08.738319Z","shell.execute_reply.started":"2021-10-07T11:00:08.728407Z","shell.execute_reply":"2021-10-07T11:00:08.737544Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"net=densenet(1,10)\noptimizer = torch.optim.SGD(net.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:00:08.739860Z","iopub.execute_input":"2021-10-07T11:00:08.740612Z","iopub.status.idle":"2021-10-07T11:00:08.763992Z","shell.execute_reply.started":"2021-10-07T11:00:08.740572Z","shell.execute_reply":"2021-10-07T11:00:08.763310Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train(net, train_data, test_data, 20, optimizer, criterion)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:00:08.765224Z","iopub.execute_input":"2021-10-07T11:00:08.765470Z","iopub.status.idle":"2021-10-07T11:09:56.068453Z","shell.execute_reply.started":"2021-10-07T11:00:08.765439Z","shell.execute_reply":"2021-10-07T11:09:56.067673Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"简化了的模型也能在训练20次时达到0.992682的测试集准确率","metadata":{}}]}