{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torchvision.datasets import mnist\nfrom torch.utils.data import DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-01T23:42:53.786075Z","iopub.execute_input":"2021-10-01T23:42:53.787032Z","iopub.status.idle":"2021-10-01T23:42:53.793994Z","shell.execute_reply.started":"2021-10-01T23:42:53.786982Z","shell.execute_reply":"2021-10-01T23:42:53.792544Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"markdown","source":"vgg 的一个关键就是使用很多层 3 x 3 的卷积然后再使用一个最大池化层。\n\n我们可以定义一个 vgg 的 block，传入三个参数，第一个是模型层数，第二个是输入的通道数，第三个是输出的通道数，第一层卷积接受的输入通道就是图片输入的通道数，然后输出最后的输出通道数，后面的卷积接受的通道数就是最后的输出通道数","metadata":{}},{"cell_type":"code","source":"def vgg_block(num_convs, in_channels, out_channels):\n    net = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), nn.ReLU(True)] # 定义第一层\n    \n    for i in range(num_convs-1): # 定义后面的很多层\n        net.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n        net.append(nn.ReLU(True))\n        \n    net.append(nn.MaxPool2d(2, 2)) # 定义池化层\n    return nn.Sequential(*net)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T23:42:53.796310Z","iopub.execute_input":"2021-10-01T23:42:53.796908Z","iopub.status.idle":"2021-10-01T23:42:53.804823Z","shell.execute_reply.started":"2021-10-01T23:42:53.796869Z","shell.execute_reply":"2021-10-01T23:42:53.804043Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"markdown","source":"下面我们定义一个函数对这个 vgg block 进行堆叠","metadata":{}},{"cell_type":"code","source":"def vgg_stack(num_convs, channels):\n    net = []\n    for n, c in zip(num_convs, channels):\n        in_c = c[0]\n        out_c = c[1]\n        net.append(vgg_block(n, in_c, out_c))\n    return nn.Sequential(*net)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T23:42:53.807579Z","iopub.execute_input":"2021-10-01T23:42:53.807803Z","iopub.status.idle":"2021-10-01T23:42:53.817353Z","shell.execute_reply.started":"2021-10-01T23:42:53.807775Z","shell.execute_reply":"2021-10-01T23:42:53.816549Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":"我们定义一个稍微简单一点的 vgg 结构，其中有 3 个卷积层","metadata":{}},{"cell_type":"code","source":"vgg_net = vgg_stack((1, 2), ((1, 3), (3, 6)))\nprint(vgg_net)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T23:42:53.820866Z","iopub.execute_input":"2021-10-01T23:42:53.821135Z","iopub.status.idle":"2021-10-01T23:42:53.831711Z","shell.execute_reply.started":"2021-10-01T23:42:53.821096Z","shell.execute_reply":"2021-10-01T23:42:53.830835Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"class vgg(nn.Module):\n    def __init__(self):\n        super(vgg, self).__init__()\n        self.feature = vgg_net\n        self.fc = nn.Sequential(\n            nn.Linear(294, 16),\n            nn.ReLU(True),\n            nn.Linear(16, 10)\n        )\n    def forward(self, x):\n#         print(\"shape1:\"+str(x.shape))\n        x = self.feature(x.float())\n#         print(\"shape2:\"+str(x.shape))\n        x = x.view(x.shape[0], -1)\n#         print(\"shape3:\"+str(x.shape))\n        x = self.fc(x)\n#         print(\"shape4:\"+str(x.shape))\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-01T23:42:53.835972Z","iopub.execute_input":"2021-10-01T23:42:53.836312Z","iopub.status.idle":"2021-10-01T23:42:53.845546Z","shell.execute_reply.started":"2021-10-01T23:42:53.836274Z","shell.execute_reply":"2021-10-01T23:42:53.844536Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\n\ndef get_acc(output, label):\n    total = output.shape[0]\n    _, pred_label = output.max(1)\n    num_correct = (pred_label == label).sum().data\n    return num_correct / total\n\n\ndef train(net, train_data, valid_data, num_epochs, optimizer, criterion):\n    if torch.cuda.is_available():\n        net = net.cuda()\n    prev_time = datetime.now()\n    for epoch in range(num_epochs):\n        train_loss = 0\n        train_acc = 0\n        net = net.train()\n        for im, label in train_data:\n            if torch.cuda.is_available():\n                im = Variable(im.cuda())  # (bs, 3, h, w)\n                label = Variable(label.cuda())  # (bs, h, w)\n            else:\n                im = Variable(im)\n                label = Variable(label)\n            # forward\n            output = net(im)\n            loss = criterion(output, label)\n            # backward\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.data\n            train_acc += get_acc(output, label)\n\n        cur_time = datetime.now()\n        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n        m, s = divmod(remainder, 60)\n        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n        if valid_data is not None:\n            valid_loss = 0\n            valid_acc = 0\n            net = net.eval()\n            for im, label in valid_data:\n                if torch.cuda.is_available():\n                    im = Variable(im.cuda())\n                    label = Variable(label.cuda())\n                else:\n                    im = Variable(im)\n                    label = Variable(label)\n                output = net(im)\n                loss = criterion(output, label)\n                valid_loss += loss.data\n                valid_acc += get_acc(output, label)\n            epoch_str = (\n                \"Epoch %d. Train Loss: %f, Train Acc: %f, Valid Loss: %f, Valid Acc: %f, \"\n                % (epoch, train_loss / len(train_data),\n                   train_acc / len(train_data), valid_loss / len(valid_data),\n                   valid_acc / len(valid_data)))\n        else:\n            epoch_str = (\"Epoch %d. Train Loss: %f, Train Acc: %f, \" %\n                         (epoch, train_loss / len(train_data),\n                          train_acc / len(train_data)))\n        prev_time = cur_time\n        print(epoch_str + time_str)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T23:42:53.848883Z","iopub.execute_input":"2021-10-01T23:42:53.849131Z","iopub.status.idle":"2021-10-01T23:42:53.868863Z","shell.execute_reply.started":"2021-10-01T23:42:53.849104Z","shell.execute_reply":"2021-10-01T23:42:53.867897Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"def data_tf(x):\n    x = np.array(x, dtype='float32') / 255\n    x = (x - 0.5) / 0.5 # 数据预处理，标准化\n    x=np.array([x.tolist()])\n    x = torch.from_numpy(x)    \n    return x","metadata":{"execution":{"iopub.status.busy":"2021-10-01T23:42:53.870357Z","iopub.execute_input":"2021-10-01T23:42:53.870707Z","iopub.status.idle":"2021-10-01T23:42:53.880895Z","shell.execute_reply.started":"2021-10-01T23:42:53.870678Z","shell.execute_reply":"2021-10-01T23:42:53.880080Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import mnist # 导入 pytorch 内置的 mnist 数据\ntrain_set = mnist.MNIST('./data', train=True, transform=data_tf,download=True) # 重新载入数据集，申明定义的数据变换\ntest_set = mnist.MNIST('./data', train=False, transform=data_tf,download=True)\ntrain_data = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\ntest_data = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T23:42:53.882541Z","iopub.execute_input":"2021-10-01T23:42:53.883011Z","iopub.status.idle":"2021-10-01T23:42:53.922657Z","shell.execute_reply.started":"2021-10-01T23:42:53.882970Z","shell.execute_reply":"2021-10-01T23:42:53.921826Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"x=torch.tensor([])\nfor i,j in train_data:\n#     print(i[0].shape) \n#     print(i[0])\n    x=i\n    break\nprint(x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T23:42:53.924021Z","iopub.execute_input":"2021-10-01T23:42:53.924432Z","iopub.status.idle":"2021-10-01T23:42:53.952557Z","shell.execute_reply.started":"2021-10-01T23:42:53.924393Z","shell.execute_reply":"2021-10-01T23:42:53.951738Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"x=Variable(x.cuda())\nvgg_net=vgg_net.cuda()\nx=vgg_net(x.float())\nprint(x.shape)\nx = x.view(x.shape[0], -1)\nprint(x.shape)\nfc = nn.Sequential(\n        nn.Linear(294, 16),\n        nn.ReLU(True),\n        nn.Linear(16, 10)\n        )\nx = fc.cuda()(x)\nprint(x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T23:42:53.953857Z","iopub.execute_input":"2021-10-01T23:42:53.954668Z","iopub.status.idle":"2021-10-01T23:42:53.967459Z","shell.execute_reply.started":"2021-10-01T23:42:53.954615Z","shell.execute_reply":"2021-10-01T23:42:53.966427Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"net = vgg()\noptimizer = torch.optim.SGD(net.parameters(), lr=1e-1)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2021-10-01T23:42:53.968958Z","iopub.execute_input":"2021-10-01T23:42:53.969371Z","iopub.status.idle":"2021-10-01T23:42:53.977094Z","shell.execute_reply.started":"2021-10-01T23:42:53.969329Z","shell.execute_reply":"2021-10-01T23:42:53.975940Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"train(net, train_data, test_data, 20, optimizer, criterion)","metadata":{"execution":{"iopub.status.busy":"2021-10-01T23:42:53.978958Z","iopub.execute_input":"2021-10-01T23:42:53.979271Z","iopub.status.idle":"2021-10-01T23:44:52.253264Z","shell.execute_reply.started":"2021-10-01T23:42:53.979231Z","shell.execute_reply":"2021-10-01T23:44:52.251812Z"},"trusted":true},"execution_count":129,"outputs":[]}]}